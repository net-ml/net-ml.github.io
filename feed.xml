<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" xml:lang="en"><generator uri="https://jekyllrb.com/" version="4.3.4">Jekyll</generator><link href="https://netml.io/feed.xml" rel="self" type="application/atom+xml"/><link href="https://netml.io/" rel="alternate" type="text/html" hreflang="en"/><updated>2025-01-10T14:53:16+00:00</updated><id>https://netml.io/feed.xml</id><title type="html">NetML</title><subtitle>A place where to collect all our ideas about the world of Machine Learning and Networking. </subtitle><entry><title type="html">Introducing NetDiffusion: A New Direction in Network Data Augmentation</title><link href="https://netml.io/blog/2024/netdiffusion/" rel="alternate" type="text/html" title="Introducing NetDiffusion: A New Direction in Network Data Augmentation"/><published>2024-03-18T00:00:00+00:00</published><updated>2024-03-18T00:00:00+00:00</updated><id>https://netml.io/blog/2024/netdiffusion</id><content type="html" xml:base="https://netml.io/blog/2024/netdiffusion/"><![CDATA[<p>See our open-sourced repo for implementation details: https://github.com/noise-lab/NetDiffusion_Generator</p> <p>In the world of machine learning (ML) for network management and security, the scarcity of high-quality, labeled network datasets has always been a major bottleneck. Traditional methods for generating synthetic network data, while useful, have struggled to produce the level of detail and realism required for effective ML model training. This is where our latest research comes into play. Our paper, “NetDiffusion: Network Data Augmentation Through Protocol-Constrained Traffic Generation,” presents a groundbreaking tool designed to bridge this gap by using diffusion models to generate synthetic network traffic that is not only high in fidelity but also adheres to protocol specifications. For more details regarding the tool, please refer to our full paper (https://dl.acm.org/doi/pdf/10.1145/3639037).</p> <figure align="center"> <figcaption>NetDiffusion Pipeline:</figcaption> <img src="https://github.com/noise-lab/NetDiffusion_Generator/assets/47127634/804756f9-156e-4796-bea6-00d5d7bb1706" alt="Screenshot 2024-02-29 at 3 41 29 PM" width="1241"/> </figure> <h1 id="why-netdiffusion">Why NetDiffusion?</h1> <p>Our motivation stems from the limitations of current synthetic data generation methods, which primarily focus on aggregated statistics or selected packet attributes. These methods often fall short, particularly when training ML models that rely on detailed features only available in packet traces. NetDiffusion addresses these challenges head-on. It leverages a finely-tuned, controlled variant of a Stable Diffusion model to create synthetic network traffic that closely mimics real-world data in both statistical behavior and compliance with network protocols.</p> <h1 id="how-netdiffusion-works">How NetDiffusion Works</h1> <p>NetDiffusion operates in three key stages:</p> <p><strong>Network Traffic to Image Conversion</strong>: We convert raw network traffic into image-based representations. This innovative approach allows us to leverage the advanced capabilities of diffusion models, which excel in generating high-quality images from textual descriptions.</p> <div align="center"> <img src="https://github.com/net-ml/net-ml.github.io/assets/47127634/f6103b57-5c93-4847-8c72-9c9a41b58b70" alt="Screenshot 2024-02-29 at 3 41 29 PM" width="600"/> </div> <p><strong>Fine-Tuning Diffusion Model for Network Traffic Generation</strong>: By fine-tuning a diffusion model on network traffic images, NetDiffusion can generate synthetic data that preserves the intricate patterns found in real network traffic.</p> <div align="center"> <img src="https://github.com/net-ml/net-ml.github.io/assets/47127634/90af5e42-e229-4ffb-a013-2800264fa8e2" alt="Screenshot 2024-02-29 at 3 41 29 PM" width="800"/> </div> <p><strong>Ensuring Protocol Compliance</strong>: A significant contribution of NetDiffusion is its ability to generate synthetic data that adheres to inter and intra-packet network protocol rules through post-generation heuristic. This ensures that the generated traffic can be readily used for a wide range of network analysis and testing tasks beyond ML applications.</p> <div align="center"> <img src="https://github.com/net-ml/net-ml.github.io/assets/47127634/438e4c0f-1b89-4d36-a775-9611fbb41781" alt="Screenshot 2024-02-29 at 3 41 29 PM" width="700"/> </div> <h1 id="evaluation-and-impact">Evaluation and Impact</h1> <p>We evaluate the quality of NetDiffusion-synthetic traces by using it to generate network flows for ten different applications and services. Our evaluation demonstrates that NetDiffusion-generated data achieves higher statistical similarity to real data compared to existing state-of-the-art methods.</p> <div align="center"> <img src="https://github.com/net-ml/net-ml.github.io/assets/47127634/6999e559-bec7-4e82-b593-fa4806864eb9" alt="Screenshot 2024-02-29 at 3 41 29 PM" width="500"/> </div> <p>We also look at the scenarios where the training of ML models is done using a mixture of both real and synthetic data, and across all scenarios, ML models that use our synthetic data is able to outperform those that use other synthetic data.</p> <div align="center"> <img src="https://github.com/net-ml/net-ml.github.io/assets/47127634/cc610302-af90-40ee-8ee0-6c4d87a89922" alt="Screenshot 2024-02-29 at 3 41 29 PM" width="800"/> </div> <p>Lastly, we try to use synthetic data to solve the problem of class imbalance where we populate underrepresented classes using the synthetic data points. we observe notable ML accuracy improvement when we carry out class balancing using NetDiffusion data, particularly for classes that are underrepresented such as Facebook, Meet, and Zoom in this case.</p> <div align="center"> <img src="https://github.com/net-ml/net-ml.github.io/assets/47127634/2afd2e9e-878e-48fd-a7e4-fee725dbf28d" alt="Screenshot 2024-02-29 at 3 41 29 PM" width="500"/> </div> <p>Furthermore, the generated synthetic network traffic supports traditional network analysis and testing tasks, showcasing NetDiffusion’s versatility and potential to serve a broad spectrum of network research and development needs.</p> <div align="center"> <img src="https://github.com/net-ml/net-ml.github.io/assets/47127634/f76240c2-a54f-421f-b057-c15f3e87dea3" alt="Screenshot 2024-02-29 at 3 41 29 PM" width="500"/> </div> <h1 id="open-source-and-future-directions">Open Source and Future Directions</h1> <p>We are committed to contributing to the research community and have made our pipeline available on GitHub (https://github.com/noise-lab/NetDiffusion_Generator/tree/main). Looking ahead, we see numerous opportunities to enhance NetDiffusion, including exploring more sophisticated conditioning techniques for diffusion models and extending its applicability to even more diverse network scenarios.</p> <h1 id="concluding-thoughts">Concluding Thoughts</h1> <p>NetDiffusion represents a significant step forward in network data augmentation. By addressing the critical need for detailed and protocol-compliant synthetic network data, it opens new avenues for research and development in network management, security, and beyond. We are excited about the potential of NetDiffusion and look forward to its adoption and evolution within the research community.</p>]]></content><author><name>Xi (Chase) Jiang</name></author><category term="research"/><category term="generative,"/><category term="dataset,"/><category term="code"/><summary type="html"><![CDATA[See our open-sourced repo for implementation details: https://github.com/noise-lab/NetDiffusion_Generator]]></summary></entry><entry><title type="html">AMIR will appear at ACM Ubicomp 2023</title><link href="https://netml.io/blog/2023/amir/" rel="alternate" type="text/html" title="AMIR will appear at ACM Ubicomp 2023"/><published>2023-04-03T13:00:00+00:00</published><updated>2023-04-03T13:00:00+00:00</updated><id>https://netml.io/blog/2023/amir</id><content type="html" xml:base="https://netml.io/blog/2023/amir/"><![CDATA[<h1 id="amir-active-multimodal-interaction-recognition-from-video-and-network-traffic-in-connected-environments">AMIR: Active Multimodal Interaction Recognition from Video and Network Traffic in Connected Environments</h1> <p><em>Abstract.</em> Activity recognition using video data is widely adopted for elder care, monitoring for safety and security, and home automation. Unfortunately, using video data as the basis for activity recognition can be brittle, since models trained on video are often not robust to certain environmental changes, such as camera angle and lighting changes. There has been a proliferation of network-connected devices in home environments. Interactions with these smart devices are associated with network activity, making network data a potential source for recognizing these device interactions. This paper advocates for the synthesis of video and network data for robust interaction recognition in connected environments. We consider machine learning-based approaches for activity recognition, where each labeled activity is associated with both a video capture and an accompanying network traffic trace. We develop a simple but effective framework AMIR (Active Multimodal Interaction Recognition)1 that trains independent models for video and network activity recognition respectively, and subsequently combines the predictions from these models using a meta-learning framework. Whether in lab or at home, this approach reduces the amount of “paired” demonstrations needed to perform accurate activity recognition, where both network and video data are collected simultaneously. Specifically, the method we have developed requires up to 70.83% fewer samples to achieve 85% F1 score than random data collection, and improves accuracy by 17.76% given the same number of samples.</p> <h2 id="resources">Resources</h2> <p>You can access the source code of the project as well as detailed documentation at <a href="https://amir-vidnet.github.io">https://amir-vidnet.github.io</a></p> <h3 id="citation-bibtex">Citation bibtex</h3> <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>@article{liu2023amir,
  title={AMIR: Active Multimodal Interaction Recognition from Video and Network Traffic in Connected Environments},
  author={Liu, Shinan and Mangla, Tarun and Shaowang, Ted and Zhao, Jinjin and Paparrizos, John and Krishnan, Sanjay and Feamster, Nick},
  journal={Proceedings of the ACM on Interactive, Mobile, Wearable and Ubiquitous Technologies},
  volume={7},
  number={1},
  pages={1--26},
  year={2023},
  publisher={ACM New York, NY, USA}
}
</code></pre></div></div>]]></content><author><name></name></author><category term="code"/><summary type="html"><![CDATA[AMIR: Active Multimodal Interaction Recognition from Video and Network Traffic in Connected Environments]]></summary></entry><entry><title type="html">LEAF will appear at ACM CoNEXT 2023</title><link href="https://netml.io/blog/2023/leaf/" rel="alternate" type="text/html" title="LEAF will appear at ACM CoNEXT 2023"/><published>2023-04-03T13:00:00+00:00</published><updated>2023-04-03T13:00:00+00:00</updated><id>https://netml.io/blog/2023/leaf</id><content type="html" xml:base="https://netml.io/blog/2023/leaf/"><![CDATA[<h1 id="leaf-navigating-concept-drift-in-cellular-networks">LEAF: Navigating Concept Drift in Cellular Networks</h1> <p><em>Abstract.</em> Operational networks commonly rely on machine learning models for many tasks, including detecting anomalies, inferring application performance, and forecasting demand. Yet, model accuracy can degrade due to concept drift, where either the relationships between features and the target to be predicted, or the features themselves change. Mitigating concept drift is an essential part of operationalizing machine learning models in general, but is of particular importance in networking’s highly dynamic deployment environments. In this paper, we first characterize concept drift in a large cellular network for a major metropolitan area in the United States. We find that concept drift occurs across many important key performance indicators (KPIs), independently of the model, training set size, and time interval—thus necessitating practical approaches to detect, explain, and mitigate it. We then show that frequent model retraining with newly available data is not sufficient to mitigate concept drift, and can even degrade model accuracy further. Finally, we develop a new methodology for concept drift mitigation, Local Error Approximation of Features (LEAF). LEAF works by detecting drift; explaining the features and time intervals that contribute the most to drift; and mitigating it using forgetting and over-sampling. We evaluate LEAF against industry-standard mitigation approaches (notably, periodic retraining) with more than four years of cellular KPI data. Our tests with a major cellular provider in the US show that LEAF consistently outperforms periodic and triggered re-training on complex, real-world data while reducing costly retraining operations.</p> <h2 id="resources">Resources</h2> <p>You will soon been able to access the released dataset accompanying the paper at this page.</p> <h3 id="citation-bibtex">Citation bibtex</h3> <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>@article{liu2023leaf,
  title={LEAF: Navigating Concept Drift in Cellular Networks},
  author={Liu, Shinan and Bronzino, Francesco and Schmitt, Paul and Nitin Bhagoji, Arjun and Feamster, Nick and Crespo, Hector Garcia and Coyle, Timothy and Ward, Brian},
  journal={Proceedings of the ACM on Networking},
  year={2023}
}
</code></pre></div></div>]]></content><author><name></name></author><category term="drift,"/><category term="dataset"/><summary type="html"><![CDATA[LEAF: Navigating Concept Drift in Cellular Networks]]></summary></entry><entry><title type="html">Traffic Refinery will appear at ACM SIGMETRICS 2022</title><link href="https://netml.io/blog/2022/traffic-refinery/" rel="alternate" type="text/html" title="Traffic Refinery will appear at ACM SIGMETRICS 2022"/><published>2022-01-24T13:00:00+00:00</published><updated>2022-01-24T13:00:00+00:00</updated><id>https://netml.io/blog/2022/traffic%20refinery</id><content type="html" xml:base="https://netml.io/blog/2022/traffic-refinery/"><![CDATA[<h1 id="traffic-refinery-cost-aware-network-traffic-analysis">Traffic Refinery: Cost-aware Network Traffic Analysis.</h1> <p>Relationships between systems costs and model performance would ideally inform machine learning pipelines during design; yet, most existing network traffic representation decisions are made <em>a priori</em>, without concern for future use by models. To enable this exploration, we have created <code class="language-plaintext highlighter-rouge">Traffic Refinery</code>, a system designed to offer <strong>flexibly extensible network data representations</strong>, the ability to assess the <strong>systems-related costs</strong> of these representations, and the <strong>effects of different representations on model performance</strong>.</p> <h2 id="system-overview">System Overview</h2> <p><img src="/assets/img/system.png" alt="Traffic Refinery System Overview Diagram" align="center" height="65%" width="65%"/></p> <p>The figure shows an overview of the system architecture. <code class="language-plaintext highlighter-rouge">Traffic Refinery</code> is implemented in Go to exploit performance and flexibility, as well as its built-in benchmarking tools. The system has three components:</p> <ol> <li>A traffic categorization module responsible for associating network traffic with applications</li> <li>A packet capture and processing module that collects network flow statistics and tracks their state; moreover, this block implements a cache used to store flow state information</li> <li>An aggregation and storage module that queries the flow cache to obtain features and statistics about each traffic flow and stores higher-level features concerning the applications of interest for later processing</li> </ol> <h2 id="tldr-what-can-you-do-with-traffic-refinery">tl;dr: What Can You Do with Traffic Refinery?</h2> <ul> <li>Traffic (i.e., flows) are classified as “services” using either DNS domains or IP prefixes that the user can provide. <em>Note: DNS is increasingly encrypted, making this method less reliable. An area of ongoing research is privacy-preserving flow categorization.</em></li> <li>For each service, users can select from a set of existing features or create additional ones to collect along with their frequency.</li> <li>The system-related costs of each feature can be profiled, enabling users to explore tradeoffs between ML model performance and feature costs in their particular environment.</li> </ul> <h2 id="why-is-traffic-refinery-necessary">Why is Traffic Refinery Necessary?</h2> <p>Network management increasingly relies on machine learning to make predictions about performance and security from network traffic. Often, the representation of the traffic is as important as the choice of the model. The features that the model relies on, and the representation of those features, ultimately determine model accuracy, as well as where and whether the model can be deployed in practice. Thus, the design and evaluation of these models ultimately requires understanding not only model accuracy but also the systems costs associated with deploying the model in an operational network.</p> <p>To highlight the need for <code class="language-plaintext highlighter-rouge">Traffic Refinery</code>, we show results from our <a href="https://dl.acm.org/doi/10.1145/3366704">prior work</a> by training multiple ML models to infer the resolution of encrypted video streaming applications over time using different data representations: 1) using only L3 features, as would be available using <code class="language-plaintext highlighter-rouge">netflow</code>; 2) adding transport layer features; and 3) adding application layer features to L3; and combining all features. The figure below shows the precision and recall achieved by each representation.</p> <p><img src="/assets/img/resolution_features.png" alt="Resolution inference features" align="center" height="40%" width="40%"/></p> <p>As one might expect, a model trained solely with L3 features achieves the poorest performance. Hence, relying solely on features offered by existing network infrastructure would produce the worst performing models. On the other hand, combining Network and Application features results in more than a 10% increase in both precision and recall. This example showcases how limiting available data representations to the ones typically available from existing systems (e.g., NetFlow) can inhibit potential gains, highlighted by the blue-shaded area.</p> <p>Of course, any representation is possible if packet traces are the starting point, but raw packet capture can be prohibitive in operational networks, especially at high speeds. The figure below shows the amount of storage required to collect a one-hour packet capture from a live 10 Gbps link.</p> <p><img src="/assets/img/storage_profile.png" alt="Storage profile" align="center" height="40%" width="40%"/></p> <p><code class="language-plaintext highlighter-rouge">Traffic Refinery</code> provides a new framework and system that enables a joint evaluation of both the conventional notions of machine learning performance (e.g., model accuracy) and the systems-level costs of different representations of network traffic.</p> <h2 id="resources">Resources</h2> <p>The research paper behind <code class="language-plaintext highlighter-rouge">Traffic Refinery</code> was accepted to SIGMETRICS 2022, and published in ACM POMACS in December 2021.</p> <p>You can access the source code of the project as well as detailed documentation at <a href="https://traffic-refinery.github.io">https://traffic-refinery.github.io</a></p> <h3 id="citation-bibtex">Citation bibtex</h3> <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>@article{10.1145/3491052,
    author = {Bronzino, Francesco and Schmitt, Paul and Ayoubi, Sara and Kim, Hyojoon and Teixeira, Renata and Feamster, Nick},
    title = {Traffic Refinery: Cost-Aware Data Representation for Machine Learning on Network Traffic},
    year = {2021},
    issue_date = {December 2021},
    publisher = {Association for Computing Machinery},
    address = {New York, NY, USA},
    volume = {5},
    number = {3},
    url = {https://doi.org/10.1145/3491052},
    doi = {10.1145/3491052},
    journal = {Proc. ACM Meas. Anal. Comput. Syst.},
    month = {dec},
    articleno = {40},
    numpages = {24}
}
</code></pre></div></div>]]></content><author><name></name></author><category term="traffic-analysis,"/><category term="code"/><summary type="html"><![CDATA[A cost-aware data representation analysis system for machine learning on network traffic]]></summary></entry></feed>